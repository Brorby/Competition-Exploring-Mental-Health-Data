{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import matplotlib\n",
    "import tokenizers\n",
    "import datasets\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "\n",
    "Here we explore each feature column and comment on how we are going to preprocess each one. We have a total of 140700 samples. The last feature is the label depression which we will train on.\n",
    "\n",
    "## Id column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'id' column:\n",
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "Name: id, dtype: int64\n",
      "\n",
      "We have  140700  amount of samples\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"./Data/train.csv\")\n",
    "\n",
    "# Print examples of the 'id' column\n",
    "print(\"Examples of 'id' column:\")\n",
    "print(data[\"id\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"We have \" ,data[\"id\"].count(),\" amount of samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the id column since there is no correlation between this and the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique names sorted by count (most to least):\n",
      "Rohan: 3178\n",
      "Aarav: 2336\n",
      "Rupak: 2176\n",
      "Aaradhya: 2045\n",
      "Anvi: 2035\n",
      "Raghavendra: 1877\n",
      "Vani: 1657\n",
      "Tushar: 1596\n",
      "Ritvik: 1589\n",
      "Shiv: 1568\n",
      "Riya: 1548\n",
      "Rashi: 1547\n",
      "Raunak: 1524\n",
      "Anand: 1486\n",
      "Ishaani: 1477\n",
      "Ansh: 1423\n",
      "Vidya: 1408\n",
      "Ritika: 1313\n",
      "Anushka: 1279\n",
      "Sanya: 1272\n",
      "Aarush: 1266\n",
      "Aariv: 1254\n",
      "Abhishek: 1252\n",
      "Rupal: 1234\n",
      "Harsha: 1230\n",
      "Harsh: 1156\n",
      "Vikram: 1154\n",
      "Shivam: 1146\n",
      "Raghav: 1120\n",
      "Armaan: 1116\n",
      "Prachi: 1104\n",
      "Ivaan: 1090\n",
      "Ayaan: 1090\n",
      "Siddhesh: 1090\n",
      "Ira: 1061\n",
      "Prisha: 1055\n",
      "Rahil: 1051\n",
      "Rishi: 1040\n",
      "Ritik: 1033\n",
      "Pratham: 1023\n",
      "Aniket: 1023\n",
      "Chhavi: 1003\n",
      "Vibha: 974\n",
      "Vivan: 963\n",
      "Aishwarya: 962\n",
      "Gauri: 959\n",
      "Nikita: 951\n",
      "Naina: 946\n",
      "Veda: 940\n",
      "Arav: 925\n",
      "Vidhi: 913\n",
      "Jiya: 912\n",
      "Advait: 910\n",
      "Krishna: 875\n",
      "Vedant: 872\n",
      "Ayush: 869\n",
      "Aditi: 851\n",
      "Shaurya: 848\n",
      "Kashish: 845\n",
      "Gagan: 842\n",
      "Eshita: 831\n",
      "Pratyush: 816\n",
      "Ila: 799\n",
      "Simran: 790\n",
      "Aadhya: 787\n",
      "Shreya: 784\n",
      "Rudransh: 776\n",
      "Garima: 769\n",
      "Yashvi: 767\n",
      "Anjali: 757\n",
      "Vihaan: 744\n",
      "Keshav: 737\n",
      "Yuvraj: 730\n",
      "Ishan: 714\n",
      "Tanisha: 713\n",
      "Harshil: 712\n",
      "Sanket: 710\n",
      "Rajat: 706\n",
      "Kunal: 700\n",
      "Nikhil: 690\n",
      "Kiran: 687\n",
      "Aanchal: 684\n",
      "Zara: 681\n",
      "Shlok: 672\n",
      "Nandini: 663\n",
      "Pranav: 655\n",
      "Mahika: 652\n",
      "Kavya: 643\n",
      "Jhanvi: 635\n",
      "Esha: 632\n",
      "Satyam: 632\n",
      "Reyansh: 627\n",
      "Shrey: 626\n",
      "Janvi: 611\n",
      "Anaya: 610\n",
      "Anirudh: 606\n",
      "Arnav: 595\n",
      "Aahana: 593\n",
      "Aarti: 586\n",
      "Pallavi: 586\n",
      "Amit: 583\n",
      "Ishwar: 574\n",
      "Utkarsh: 547\n",
      "Siddharth: 539\n",
      "Saanvi: 537\n",
      "Asha: 534\n",
      "Darsh: 526\n",
      "Abhinav: 524\n",
      "Anika: 520\n",
      "Parth: 518\n",
      "Aditya: 512\n",
      "Aarohi: 504\n",
      "Nishant: 501\n",
      "Tanya: 501\n",
      "Rhea: 499\n",
      "Samar: 498\n",
      "Chirag: 493\n",
      "Kriti: 490\n",
      "Manvi: 486\n",
      "Divya: 481\n",
      "Kabir: 481\n",
      "Pooja: 481\n",
      "Kian: 481\n",
      "Hrithik: 475\n",
      "Shruti: 467\n",
      "Ayansh: 461\n",
      "Mahi: 461\n",
      "Trisha: 458\n",
      "Kartikeya: 456\n",
      "Atharv: 438\n",
      "Monika: 433\n",
      "Mihir: 433\n",
      "Shivansh: 419\n",
      "Tanmay: 418\n",
      "Arjun: 403\n",
      "Diya: 391\n",
      "Yash: 389\n",
      "Charvi: 387\n",
      "Sanjeev: 387\n",
      "Vrinda: 383\n",
      "Sai: 382\n",
      "Aryan: 379\n",
      "Manan: 378\n",
      "Ishita: 377\n",
      "Virat: 374\n",
      "Damini: 374\n",
      "Bhavesh: 362\n",
      "Khushi: 356\n",
      "Ishaan: 355\n",
      "Nalini: 353\n",
      "Jai: 343\n",
      "Neha: 342\n",
      "Palak: 339\n",
      "Yogesh: 338\n",
      "Gaurav: 336\n",
      "Deepak: 335\n",
      "Dhruv: 334\n",
      "Tara: 331\n",
      "Vivaan: 329\n",
      "Pari: 319\n",
      "Lavanya: 315\n",
      "Aakash: 313\n",
      "Navya: 311\n",
      "Leela: 310\n",
      "Siddhi: 310\n",
      "Soham: 306\n",
      "Tanvi: 300\n",
      "Kartik: 296\n",
      "Arya: 289\n",
      "Tina: 285\n",
      "Vanya: 280\n",
      "Kush: 274\n",
      "Isha: 266\n",
      "Nisha: 264\n",
      "Samaira: 263\n",
      "Suhani: 261\n",
      "Saurav: 258\n",
      "Apoorva: 252\n",
      "Yamini: 250\n",
      "Aarya: 247\n",
      "Neil: 244\n",
      "Karishma: 240\n",
      "Lata: 237\n",
      "Zoya: 232\n",
      "Nirvaan: 231\n",
      "Rudra: 220\n",
      "Vaishnavi: 217\n",
      "Om: 216\n",
      "Mayank: 215\n",
      "Dev: 210\n",
      "Vaanya: 209\n",
      "Nakul: 206\n",
      "Rajveer: 199\n",
      "Himani: 196\n",
      "Barkha: 190\n",
      "Tejas: 185\n",
      "Sneha: 180\n",
      "Bhavna: 167\n",
      "Ranveer: 162\n",
      "Rupa: 151\n",
      "Srishti: 150\n",
      "Kiara: 138\n",
      "Kanika: 138\n",
      "Mira: 137\n",
      "Mithila: 132\n",
      "Radhika: 122\n",
      "Sara: 108\n",
      "Pihu: 104\n",
      "Varun: 97\n",
      "Jasmine: 94\n",
      "Lakshay: 80\n",
      "Avni: 71\n",
      "Shanaya: 65\n",
      "Mukund: 57\n",
      "Meera: 51\n",
      "Harini: 47\n",
      "Kalyan: 21\n",
      "Aarash: 3\n",
      "Rupar: 3\n",
      "Kolkata: 3\n",
      "Tarsh: 3\n",
      "Shivvi: 2\n",
      "Prishti: 2\n",
      "Pradhya: 2\n",
      "Aisha: 2\n",
      "Aanya: 2\n",
      "Rani: 2\n",
      "Patna: 2\n",
      "Hra: 2\n",
      "Shivna: 2\n",
      "Siddh: 2\n",
      "Vashi: 2\n",
      "Aarvi: 2\n",
      "Thane: 2\n",
      "Jhaan: 2\n",
      "Kartika: 2\n",
      "Aniv: 2\n",
      "Aam: 2\n",
      "Shivar: 2\n",
      "Shivan: 2\n",
      "Aan: 2\n",
      "Nanya: 2\n",
      "Rupadhya: 2\n",
      "Anya: 2\n",
      "Rupika: 1\n",
      "Aaransh: 1\n",
      "Ijra: 1\n",
      "Aikash: 1\n",
      "Anishi: 1\n",
      "Aaranya: 1\n",
      "Anar: 1\n",
      "Parha: 1\n",
      "Srinagar: 1\n",
      "Vidha: 1\n",
      "Prayat: 1\n",
      "Yurav: 1\n",
      "Shivak: 1\n",
      "Rupai: 1\n",
      "Arvik: 1\n",
      "Manjun: 1\n",
      "Ranchal: 1\n",
      "Vita: 1\n",
      "Prandini: 1\n",
      "Mahav: 1\n",
      "Nhanini: 1\n",
      "Anupal: 1\n",
      "Manr: 1\n",
      "Eikram: 1\n",
      "Arsha: 1\n",
      "Harshir: 1\n",
      "Shivlok: 1\n",
      "Shivwar: 1\n",
      "Abarav: 1\n",
      "Ayya: 1\n",
      "Rudrithik: 1\n",
      "Varanasi: 1\n",
      "K.Pharm: 1\n",
      "UX/UI Designer: 1\n",
      "Ariti: 1\n",
      "Nhanvi: 1\n",
      "Aarani: 1\n",
      "Jiram: 1\n",
      "M.Tech: 1\n",
      "Kike: 1\n",
      "Shivvaan: 1\n",
      "Aarla: 1\n",
      "Nishi: 1\n",
      "Aarand: 1\n",
      "Adiya: 1\n",
      "Ritak: 1\n",
      "Kashi: 1\n",
      "Krey: 1\n",
      "Prarav: 1\n",
      "Kartal: 1\n",
      "Anariv: 1\n",
      "Irit: 1\n",
      "Kanisha: 1\n",
      "Anisha: 1\n",
      "Harshaun: 1\n",
      "Rietvik: 1\n",
      "Vasai-Virar: 1\n",
      "Ishlok: 1\n",
      "Vika: 1\n",
      "Rika: 1\n",
      "Shir: 1\n",
      "Sharth: 1\n",
      "Rudrey: 1\n",
      "Virar: 1\n",
      "Shashi: 1\n",
      "Eisha: 1\n",
      "Vhaani: 1\n",
      "Prilak: 1\n",
      "Tani: 1\n",
      "Nya: 1\n",
      "Harshav: 1\n",
      "Ewesh: 1\n",
      "Aanket: 1\n",
      "Tohar: 1\n",
      "Ryouvik: 1\n",
      "Niya: 1\n",
      "Anjun: 1\n",
      "Rupat: 1\n",
      "Anahk: 1\n",
      "Shivsh: 1\n",
      "Niki: 1\n",
      "Nishita: 1\n",
      "Rohik: 1\n",
      "Prishi: 1\n",
      "Ishaansh: 1\n",
      "Harshand: 1\n",
      "Manik: 1\n",
      "Chrinda: 1\n",
      "Aavya: 1\n",
      "Anarush: 1\n",
      "Viv: 1\n",
      "Ronnie: 1\n",
      "18: 1\n",
      "Rietal: 1\n",
      "R.Com: 1\n",
      "Anohi: 1\n",
      "Vivani: 1\n",
      "Ayash: 1\n",
      "Anil: 1\n",
      "Aiya: 1\n",
      "Tinmay: 1\n",
      "Rhesh: 1\n",
      "Nikya: 1\n",
      "Arnar: 1\n",
      "Vakash: 1\n",
      "Jush: 1\n",
      "Randik: 1\n",
      "Siddir: 1\n",
      "Raghavvi: 1\n",
      "BE: 1\n",
      "Anakash: 1\n",
      "Taurav: 1\n",
      "Ishaesh: 1\n",
      "A.Ed: 1\n",
      "Golkut: 1\n",
      "Krav: 1\n",
      "Ayhan: 1\n",
      "Parvik: 1\n",
      "Vlaan: 1\n",
      "Mahak: 1\n",
      "Abishma: 1\n",
      "Prvi: 1\n",
      "K. Kavya: 1\n",
      "Aieter: 1\n",
      "Aarsh: 1\n",
      "Kupa: 1\n",
      "Rudegrav: 1\n",
      "Parvi: 1\n",
      "Rajankot: 1\n",
      "Ani: 1\n",
      "Rupil: 1\n",
      "Adachi: 1\n",
      "Ayut: 1\n",
      "Rajya: 1\n",
      "Vidvi: 1\n",
      "Mahir: 1\n",
      "Sansh: 1\n",
      "Prishant: 1\n",
      "Eirini: 1\n",
      "Tanak: 1\n",
      "Researcher: 1\n",
      "Shaina: 1\n",
      "Aani: 1\n",
      "Plumber: 1\n",
      "Nanchal: 1\n",
      "Ayoub: 1\n",
      "Airav: 1\n",
      "Zegmay: 1\n",
      "Aarsush: 1\n",
      "Vidra: 1\n",
      "Kani: 1\n",
      "Ishma: 1\n",
      "Naly: 1\n",
      "Jaish: 1\n",
      "Raghavik: 1\n",
      "Anh: 1\n",
      "Pariv: 1\n",
      "Jhav: 1\n",
      "Rai: 1\n",
      "Hreya: 1\n",
      "Shivivaam: 1\n",
      "M.Com: 1\n",
      "Gavrachi: 1\n",
      "Rivaan: 1\n",
      "Haurav: 1\n",
      "Noreen: 1\n",
      "Anish: 1\n",
      "Aohi: 1\n",
      "Aariket: 1\n",
      "Aarat: 1\n",
      "Vohi: 1\n",
      "Vavya: 1\n",
      "Ishaam: 1\n",
      "Anhil: 1\n",
      "Rieta: 1\n",
      "Zahra: 1\n",
      "Jathesh: 1\n",
      "Aarun: 1\n",
      "Total unique names: 422\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each unique name\n",
    "name_counts = data[\"Name\"].value_counts()\n",
    "\n",
    "# Print results\n",
    "print(\"Unique names sorted by count (most to least):\")\n",
    "for name, count in name_counts.items():\n",
    "    print(f\"{name}: {count}\")\n",
    "\n",
    "print(f\"Total unique names: {len(name_counts)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thought about dropping the name column since we thought that this may not have any correlation to the label. But we realised that there might be a correlation, so we decided to keep it. The correlation being that for example having a \"unattractive\" name can affect your life in a bad way. \n",
    "\n",
    "\n",
    "For pre-processing this we want to give the name a value of how unique it is in the dataset, so for now we change the name with how frequent it is.\n",
    "\n",
    "\n",
    "Things to consider:\n",
    "\n",
    "Find a way to \"rate\" each name instead of how frequent the name is. Impute or change wrong names to missing name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Name' column:\n",
      "0    Female\n",
      "1      Male\n",
      "2      Male\n",
      "3      Male\n",
      "4    Female\n",
      "Name: Gender, dtype: object\n",
      "\n",
      "Number of unique genders: 2\n"
     ]
    }
   ],
   "source": [
    "# Print examples of the 'Name' column\n",
    "print(\"Examples of 'Name' column:\")\n",
    "print(data[\"Gender\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique genders:\", data[\"Gender\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will just encode male to 1 and female to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Age' column:\n",
      "0    49.0\n",
      "1    26.0\n",
      "2    33.0\n",
      "3    22.0\n",
      "4    30.0\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "Number of unique ages: 43\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Age' column:\")\n",
    "print(data[\"Age\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique ages:\", data[\"Age\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only change the number from float to integer.\n",
    "\n",
    "# Academic pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Academic pressure' column:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    5.0\n",
      "3    NaN\n",
      "4    NaN\n",
      "Name: Academic Pressure, dtype: float64\n",
      "\n",
      "Number of unique Academic pressures: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Academic pressure' column:\")\n",
    "print(data[\"Academic Pressure\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Academic pressures:\", data[\"Academic Pressure\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the \"Academic Pressure\" column we want to replace NaN with zeros.\n",
    "\n",
    "# Family History of Mental Illnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Family History of Mental Illness' column:\n",
      "0     No\n",
      "1     No\n",
      "2     No\n",
      "3    Yes\n",
      "4    Yes\n",
      "Name: Family History of Mental Illness, dtype: object\n",
      "\n",
      "Number of unique Family History of Mental Illnesses: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Family History of Mental Illness' column:\")\n",
    "print(data[\"Family History of Mental Illness\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Family History of Mental Illnesses:\", data[\"Family History of Mental Illness\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this column we will change yes and no to 1 and 0\n",
    "\n",
    "# Have you ever had suicidal thoughts ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Have you ever had suicidal thoughts ?' column:\n",
      "0     No\n",
      "1    Yes\n",
      "2    Yes\n",
      "3    Yes\n",
      "4    Yes\n",
      "Name: Have you ever had suicidal thoughts ?, dtype: object\n",
      "\n",
      "Number of unique Have you ever had suicidal thoughts ?: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Have you ever had suicidal thoughts ?' column:\")\n",
    "print(data[\"Have you ever had suicidal thoughts ?\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Have you ever had suicidal thoughts ?:\", data[\"Have you ever had suicidal thoughts ?\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also change this column to binary no / yes to 0 / 1\n",
    "\n",
    "# Working Professional or Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Working Professional or Student' column:\n",
      "0    Working Professional\n",
      "1    Working Professional\n",
      "2                 Student\n",
      "3    Working Professional\n",
      "4    Working Professional\n",
      "Name: Working Professional or Student, dtype: object\n",
      "\n",
      "Number of unique Working Professional or Student: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Working Professional or Student' column:\")\n",
    "print(data[\"Working Professional or Student\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Working Professional or Student:\", data[\"Working Professional or Student\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this column we will change \"working professional\" to 0 and \"student\" to 1.\n",
    "\n",
    "# Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Profession' column:\n",
      "0                Chef\n",
      "1             Teacher\n",
      "2                 NaN\n",
      "3             Teacher\n",
      "4    Business Analyst\n",
      "Name: Profession, dtype: object\n",
      "\n",
      "NaN is student:\n",
      "nan\n",
      "Student\n",
      "\n",
      "Number of unique Profession: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Profession' column:\")\n",
    "print(data[\"Profession\"].head())\n",
    "print(\"\")\n",
    "print(\"NaN is student:\")\n",
    "print(data[\"Profession\"][2])\n",
    "print(data[\"Working Professional or Student\"][2])\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Profession:\", data[\"Profession\"].nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are occurences of NaN in this column, this happens when the sample is a student. We find it reasonable to insert \"Student\" in those slots. there are also occurences of NaN on samples that are not students, here we will insert \"Missing Profession\"\n",
    "\n",
    "# Work pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Work Pressure' column:\n",
      "0    5.0\n",
      "1    4.0\n",
      "2    NaN\n",
      "3    5.0\n",
      "4    1.0\n",
      "Name: Work Pressure, dtype: float64\n",
      "\n",
      "Number of unique Work Pressure: [ 5.  4. nan  1.  2.  3.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Work Pressure' column:\")\n",
    "print(data[\"Work Pressure\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Work Pressure:\", data[\"Work Pressure\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that a lower number means less work pressure, therefore We will change Nan to 0 because it is the students that has NaN on Work Pressure\n",
    "\n",
    "# CGPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'CGPA' column:\n",
      "0     NaN\n",
      "1     NaN\n",
      "2    8.97\n",
      "3     NaN\n",
      "4     NaN\n",
      "Name: CGPA, dtype: float64\n",
      "7.658636192558608\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'CGPA' column:\")\n",
    "print(data[\"CGPA\"].head())\n",
    "print(data[\"CGPA\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider changing the NaN slots to the average of the dataset, which is 7.66\n",
    "\n",
    "# Study Satisfaction and Job Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Study Satisfaction' and 'Job Satisfaction' column:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    2.0\n",
      "3    NaN\n",
      "4    NaN\n",
      "Name: Study Satisfaction, dtype: float64\n",
      "0    2.0\n",
      "1    3.0\n",
      "2    NaN\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Job Satisfaction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Study Satisfaction' and 'Job Satisfaction' column:\")\n",
    "print(data[\"Study Satisfaction\"].head())\n",
    "print(data[\"Job Satisfaction\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tell that when there is missing a value in the study satisfaction column, there is a value in the same sample but on the job satisfaction problem. these two columns complete eachother, so we will combine these two columns into one \"satisfaction\" column.\n",
    "\n",
    "# Sleep Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sleep sorted by count (most to least):\n",
      "Less than 5 hours 38784\n",
      "7-8 hours 36969\n",
      "More than 8 hours 32726\n",
      "5-6 hours 32142\n",
      "3-4 hours 12\n",
      "6-7 hours 8\n",
      "4-5 hours 7\n"
     ]
    }
   ],
   "source": [
    "sleep_counts = data[\"Sleep Duration\"].value_counts()\n",
    "\n",
    "print(\"Unique sleep sorted by count (most to least):\")\n",
    "for e, (duration, count) in enumerate(sleep_counts.items()):\n",
    "    print(duration, count)\n",
    "    if e == 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one looks a bit tricky. since there are so few occurnces of other than the four most common inputs in this feature, we will change the numbers to a scale from 1 to 4, where 1 is \"less than 5 hours\" all the way to 4 which is \"more than 8 hours\". all the others will be set to 1.\n",
    "\n",
    "# Dietary Habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sleep sorted by count (most to least):\n",
      "Moderate 49705\n",
      "Unhealthy 46227\n",
      "Healthy 44741\n",
      "Yes 2\n",
      "No 2\n",
      "More Healthy 2\n",
      "No Healthy 1\n"
     ]
    }
   ],
   "source": [
    "diet_counts = data[\"Dietary Habits\"].value_counts()\n",
    "\n",
    "print(\"Unique sleep sorted by count (most to least):\")\n",
    "for e, (diet, count) in enumerate(diet_counts.items()):\n",
    "    print(diet, count)\n",
    "    if e == 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Healthy -> 2\n",
    "* Moderate -> 1\n",
    "* Unhealthy -> 0\n",
    "* The rest -> 1\n",
    "\n",
    "# Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "Unique sleep sorted by count (most to least):\n",
      "Class 12 14729\n",
      "B.Ed 11691\n",
      "B.Arch 8742\n",
      "B.Com 8113\n",
      "B.Pharm 5856\n",
      "BCA 5739\n",
      "M.Ed 5668\n",
      "MCA 5234\n",
      "BBA 5030\n",
      "BSc 5027\n",
      "MSc 4879\n"
     ]
    }
   ],
   "source": [
    "degree_counts = data[\"Degree\"].value_counts()\n",
    "print(data[\"Degree\"].nunique())\n",
    "\n",
    "print(\"Unique sleep sorted by count (most to least):\")\n",
    "for e, (degree, count) in enumerate(degree_counts.items()):\n",
    "    print(degree, count)\n",
    "    if e == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is particularly difficult because there are 115 unique degrees and there are not just a few degrees that covers the majority of the dataset either as the case is in the dietary habit feature. Our approach here is to somehow categorize the different degrees into bachelor, master, doctrine etc. and then give each of them a number from -1 to 4 based on the rank of the degree, going from \"other\" (which is the case where we can't define what degree it is) to professional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'City' column:\n",
      "0         Ludhiana\n",
      "1         Varanasi\n",
      "2    Visakhapatnam\n",
      "3           Mumbai\n",
      "4           Kanpur\n",
      "Name: City, dtype: object\n",
      "\n",
      "Number of unique cities: 43\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'City' column:\")\n",
    "print(data[\"City\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique cities:\", data[\"Age\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique cities sorted by count (most to least):\n",
      "Kalyan: First Index = 36, Count = 6591\n",
      "Patna: First Index = 9, Count = 5924\n",
      "Vasai-Virar: First Index = 49, Count = 5765\n",
      "Kolkata: First Index = 28, Count = 5689\n",
      "Ahmedabad: First Index = 5, Count = 5613\n",
      "Meerut: First Index = 17, Count = 5528\n",
      "Ludhiana: First Index = 0, Count = 5226\n",
      "Pune: First Index = 13, Count = 5210\n",
      "Rajkot: First Index = 10, Count = 5207\n",
      "Visakhapatnam: First Index = 2, Count = 5176\n",
      "Srinagar: First Index = 26, Count = 5074\n",
      "Mumbai: First Index = 3, Count = 4966\n",
      "Indore: First Index = 189, Count = 4872\n",
      "Agra: First Index = 18, Count = 4684\n",
      "Surat: First Index = 20, Count = 4636\n",
      "Varanasi: First Index = 1, Count = 4606\n",
      "Vadodara: First Index = 43, Count = 4568\n",
      "Hyderabad: First Index = 23, Count = 4496\n",
      "Kanpur: First Index = 4, Count = 4398\n",
      "Jaipur: First Index = 12, Count = 4328\n",
      "Thane: First Index = 6, Count = 4289\n",
      "Lucknow: First Index = 16, Count = 4280\n",
      "Nagpur: First Index = 37, Count = 4209\n",
      "Bangalore: First Index = 8, Count = 4123\n",
      "Chennai: First Index = 34, Count = 4044\n",
      "Ghaziabad: First Index = 27, Count = 3620\n",
      "Delhi: First Index = 76, Count = 3593\n",
      "Bhopal: First Index = 141, Count = 3475\n",
      "Faridabad: First Index = 21, Count = 3268\n",
      "Nashik: First Index = 7, Count = 3144\n",
      "Mihir: First Index = 44166, Count = 7\n",
      "Nandini: First Index = 32706, Count = 4\n",
      "Mahi: First Index = 76335, Count = 3\n",
      "Vidya: First Index = 52500, Count = 3\n",
      "City: First Index = 34300, Count = 3\n",
      "Pratyush: First Index = 34247, Count = 3\n",
      "Harsha: First Index = 15181, Count = 3\n",
      "Saanvi: First Index = 22293, Count = 3\n",
      "Bhavna: First Index = 28862, Count = 3\n",
      "Molkata: First Index = 100610, Count = 2\n",
      "MCA: First Index = 38232, Count = 2\n",
      "M.Com: First Index = 33276, Count = 2\n",
      "Atharv: First Index = 33447, Count = 2\n",
      "Nalini: First Index = 17337, Count = 2\n",
      "Keshav: First Index = 12371, Count = 2\n",
      "Ayush: First Index = 2123, Count = 2\n",
      "M.Tech: First Index = 28672, Count = 1\n",
      "Researcher: First Index = 105684, Count = 1\n",
      "Vaishnavi: First Index = 73571, Count = 1\n",
      "Chhavi: First Index = 74881, Count = 1\n",
      "Parth: First Index = 75591, Count = 1\n",
      "Vidhi: First Index = 1190, Count = 1\n",
      "Tushar: First Index = 77791, Count = 1\n",
      "MSc: First Index = 82304, Count = 1\n",
      "No: First Index = 82472, Count = 1\n",
      "Rashi: First Index = 86723, Count = 1\n",
      "ME: First Index = 93066, Count = 1\n",
      "Ishanabad: First Index = 762, Count = 1\n",
      "Armaan: First Index = 109183, Count = 1\n",
      "Kagan: First Index = 106809, Count = 1\n",
      "Kashish: First Index = 71995, Count = 1\n",
      "Ithal: First Index = 112975, Count = 1\n",
      "Nalyan: First Index = 115761, Count = 1\n",
      "Dhruv: First Index = 116546, Count = 1\n",
      "Galesabad: First Index = 117760, Count = 1\n",
      "Itheg: First Index = 121908, Count = 1\n",
      "Aaradhya: First Index = 123642, Count = 1\n",
      "Pooja: First Index = 124395, Count = 1\n",
      "Khushi: First Index = 125289, Count = 1\n",
      "Khaziabad: First Index = 126752, Count = 1\n",
      "Jhanvi: First Index = 136563, Count = 1\n",
      "Kibara: First Index = 73510, Count = 1\n",
      "Harsh: First Index = 68667, Count = 1\n",
      "Reyansh: First Index = 70407, Count = 1\n",
      "Morena: First Index = 42134, Count = 1\n",
      "Less Delhi: First Index = 30231, Count = 1\n",
      "Malyansh: First Index = 20886, Count = 1\n",
      "Aditya: First Index = 18496, Count = 1\n",
      "Plata: First Index = 33408, Count = 1\n",
      "Aishwarya: First Index = 8772, Count = 1\n",
      "3.0: First Index = 35309, Count = 1\n",
      "Less than 5 Kalyan: First Index = 36993, Count = 1\n",
      "Krishna: First Index = 3753, Count = 1\n",
      "Mira: First Index = 38817, Count = 1\n",
      "Moreadhyay: First Index = 39217, Count = 1\n",
      "Ishkarsh: First Index = 42470, Count = 1\n",
      "Raghavendra: First Index = 22215, Count = 1\n",
      "Kashk: First Index = 43050, Count = 1\n",
      "Gurgaon: First Index = 3554, Count = 1\n",
      "Tolkata: First Index = 53366, Count = 1\n",
      "Anvi: First Index = 55970, Count = 1\n",
      "Krinda: First Index = 57185, Count = 1\n",
      "Ayansh: First Index = 58776, Count = 1\n",
      "Shrey: First Index = 60210, Count = 1\n",
      "Ivaan: First Index = 61687, Count = 1\n",
      "Vaanya: First Index = 63830, Count = 1\n",
      "Gaurav: First Index = 65042, Count = 1\n",
      "Unirar: First Index = 138190, Count = 1\n",
      "Total unique cities: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/yqb_d2815j15ggfbmhgbj8gh0000gn/T/ipykernel_64023/1198885951.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  first_occurrence = data.groupby(\"City\").apply(lambda x: x.index[0])\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each unique city\n",
    "city_counts = data[\"City\"].value_counts()\n",
    "\n",
    "# Find first occurrence index for each unique city\n",
    "first_occurrence = data.groupby(\"City\").apply(lambda x: x.index[0])\n",
    "\n",
    "# Sort cities by count in descending order\n",
    "sorted_cities = city_counts.index  # Cities sorted by count (default sorting from most to least)\n",
    "\n",
    "count = 0\n",
    "# Print results\n",
    "print(\"Unique cities sorted by count (most to least):\")\n",
    "for city in sorted_cities:\n",
    "    if city_counts[city] > 0:\n",
    "        count += 1\n",
    "        print(f\"{city}: First Index = {first_occurrence[city]}, Count = {city_counts[city]}\")\n",
    "\n",
    "print(f\"Total unique cities: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found population, density, literacy and sex ratio for each major city in our dataset. We then merged this in our data and removed city column. For the minor cities or the wrongly written cities we took the average of the other columns.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Academic pressure' column:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    5.0\n",
      "3    NaN\n",
      "4    NaN\n",
      "Name: Academic Pressure, dtype: float64\n",
      "\n",
      "Number of unique Academic pressures: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Academic pressure' column:\")\n",
    "print(data[\"Academic Pressure\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Academic pressures:\", data[\"Academic Pressure\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the \"Academic Pressure\" column we want to replace NaN with zeros.\n",
    "\n",
    "# Family History of Mental Illnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Family History of Mental Illness' column:\n",
      "0     No\n",
      "1     No\n",
      "2     No\n",
      "3    Yes\n",
      "4    Yes\n",
      "Name: Family History of Mental Illness, dtype: object\n",
      "\n",
      "Number of unique Family History of Mental Illnesses: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Family History of Mental Illness' column:\")\n",
    "print(data[\"Family History of Mental Illness\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Family History of Mental Illnesses:\", data[\"Family History of Mental Illness\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this column we will change yes and no to 1 and 0\n",
    "\n",
    "# Have you ever had suicidal thoughts ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Have you ever had suicidal thoughts ?' column:\n",
      "0     No\n",
      "1    Yes\n",
      "2    Yes\n",
      "3    Yes\n",
      "4    Yes\n",
      "Name: Have you ever had suicidal thoughts ?, dtype: object\n",
      "\n",
      "Number of unique Have you ever had suicidal thoughts ?: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Have you ever had suicidal thoughts ?' column:\")\n",
    "print(data[\"Have you ever had suicidal thoughts ?\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Have you ever had suicidal thoughts ?:\", data[\"Have you ever had suicidal thoughts ?\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also change this column to binary no / yes to 0 / 1\n",
    "\n",
    "# Working Professional or Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Working Professional or Student' column:\n",
      "0    Working Professional\n",
      "1    Working Professional\n",
      "2                 Student\n",
      "3    Working Professional\n",
      "4    Working Professional\n",
      "Name: Working Professional or Student, dtype: object\n",
      "\n",
      "Number of unique Working Professional or Student: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Working Professional or Student' column:\")\n",
    "print(data[\"Working Professional or Student\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Working Professional or Student:\", data[\"Working Professional or Student\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this column we will change \"working professional\" to 0 and \"student\" to 1.\n",
    "\n",
    "# Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Profession' column:\n",
      "0                Chef\n",
      "1             Teacher\n",
      "2                 NaN\n",
      "3             Teacher\n",
      "4    Business Analyst\n",
      "Name: Profession, dtype: object\n",
      "\n",
      "NaN is student:\n",
      "nan\n",
      "Student\n",
      "\n",
      "Number of unique Profession: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Profession' column:\")\n",
    "print(data[\"Profession\"].head())\n",
    "print(\"\")\n",
    "print(\"NaN is student:\")\n",
    "print(data[\"Profession\"][2])\n",
    "print(data[\"Working Professional or Student\"][2])\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Profession:\", data[\"Profession\"].nunique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are occurences of NaN in this column, this happens when the sample is a student. We find it reasonable to insert \"Student\" in those slots. there are also occurences of NaN on samples that are not students, here we will insert \"Missing Profession\"\n",
    "\n",
    "# Work pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Work Pressure' column:\n",
      "0    5.0\n",
      "1    4.0\n",
      "2    NaN\n",
      "3    5.0\n",
      "4    1.0\n",
      "Name: Work Pressure, dtype: float64\n",
      "\n",
      "Number of unique Work Pressure: [ 5.  4. nan  1.  2.  3.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Work Pressure' column:\")\n",
    "print(data[\"Work Pressure\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique Work Pressure:\", data[\"Work Pressure\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that a lower number means less work pressure, therefore We will change Nan to 0 because it is the students that has NaN on Work Pressure\n",
    "\n",
    "# CGPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'CGPA' column:\n",
      "0     NaN\n",
      "1     NaN\n",
      "2    8.97\n",
      "3     NaN\n",
      "4     NaN\n",
      "Name: CGPA, dtype: float64\n",
      "7.658636192558608\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'CGPA' column:\")\n",
    "print(data[\"CGPA\"].head())\n",
    "print(data[\"CGPA\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider changing the NaN slots to the average of the dataset, which is 7.66\n",
    "\n",
    "# Study Satisfaction and Job Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'Study Satisfaction' and 'Job Satisfaction' column:\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    2.0\n",
      "3    NaN\n",
      "4    NaN\n",
      "Name: Study Satisfaction, dtype: float64\n",
      "0    2.0\n",
      "1    3.0\n",
      "2    NaN\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Job Satisfaction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'Study Satisfaction' and 'Job Satisfaction' column:\")\n",
    "print(data[\"Study Satisfaction\"].head())\n",
    "print(data[\"Job Satisfaction\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tell that when there is missing a value in the study satisfaction column, there is a value in the same sample but on the job satisfaction problem. these two columns complete eachother, so we will combine these two columns into one \"satisfaction\" column.\n",
    "\n",
    "# Sleep Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sleep sorted by count (most to least):\n",
      "Less than 5 hours 38784\n",
      "7-8 hours 36969\n",
      "More than 8 hours 32726\n",
      "5-6 hours 32142\n",
      "3-4 hours 12\n",
      "6-7 hours 8\n",
      "4-5 hours 7\n"
     ]
    }
   ],
   "source": [
    "sleep_counts = data[\"Sleep Duration\"].value_counts()\n",
    "\n",
    "print(\"Unique sleep sorted by count (most to least):\")\n",
    "for e, (duration, count) in enumerate(sleep_counts.items()):\n",
    "    print(duration, count)\n",
    "    if e == 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one looks a bit tricky. since there are so few occurnces of other than the four most common inputs in this feature, we will change the numbers to a scale from 1 to 4, where 1 is \"less than 5 hours\" all the way to 4 which is \"more than 8 hours\". all the others will be set to 1.\n",
    "\n",
    "# Dietary Habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sleep sorted by count (most to least):\n",
      "Moderate 49705\n",
      "Unhealthy 46227\n",
      "Healthy 44741\n",
      "Yes 2\n",
      "No 2\n",
      "More Healthy 2\n",
      "No Healthy 1\n"
     ]
    }
   ],
   "source": [
    "diet_counts = data[\"Dietary Habits\"].value_counts()\n",
    "\n",
    "print(\"Unique sleep sorted by count (most to least):\")\n",
    "for e, (diet, count) in enumerate(diet_counts.items()):\n",
    "    print(diet, count)\n",
    "    if e == 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Healthy -> 2\n",
    "* Moderate -> 1\n",
    "* Unhealthy -> 0\n",
    "* The rest -> 1\n",
    "\n",
    "# Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "Unique sleep sorted by count (most to least):\n",
      "Class 12 14729\n",
      "B.Ed 11691\n",
      "B.Arch 8742\n",
      "B.Com 8113\n",
      "B.Pharm 5856\n",
      "BCA 5739\n",
      "M.Ed 5668\n",
      "MCA 5234\n",
      "BBA 5030\n",
      "BSc 5027\n",
      "MSc 4879\n"
     ]
    }
   ],
   "source": [
    "degree_counts = data[\"Degree\"].value_counts()\n",
    "print(data[\"Degree\"].nunique())\n",
    "\n",
    "print(\"Unique sleep sorted by count (most to least):\")\n",
    "for e, (degree, count) in enumerate(degree_counts.items()):\n",
    "    print(degree, count)\n",
    "    if e == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is particularly difficult because there are 115 unique degrees and there are not just a few degrees that covers the majority of the dataset either as the case is in the dietary habit feature. Our approach here is to somehow categorize the different degrees into bachelor, master, doctrine etc. and then give each of them a number from -1 to 4 based on the rank of the degree, going from \"other\" (which is the case where we can't define what degree it is) to professional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of 'City' column:\n",
      "0         Ludhiana\n",
      "1         Varanasi\n",
      "2    Visakhapatnam\n",
      "3           Mumbai\n",
      "4           Kanpur\n",
      "Name: City, dtype: object\n",
      "\n",
      "Number of unique cities: 43\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of 'City' column:\")\n",
    "print(data[\"City\"].head())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Number of unique cities:\", data[\"Age\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique cities sorted by count (most to least):\n",
      "Kalyan: First Index = 36, Count = 6591\n",
      "Patna: First Index = 9, Count = 5924\n",
      "Vasai-Virar: First Index = 49, Count = 5765\n",
      "Kolkata: First Index = 28, Count = 5689\n",
      "Ahmedabad: First Index = 5, Count = 5613\n",
      "Meerut: First Index = 17, Count = 5528\n",
      "Ludhiana: First Index = 0, Count = 5226\n",
      "Pune: First Index = 13, Count = 5210\n",
      "Rajkot: First Index = 10, Count = 5207\n",
      "Visakhapatnam: First Index = 2, Count = 5176\n",
      "Srinagar: First Index = 26, Count = 5074\n",
      "Mumbai: First Index = 3, Count = 4966\n",
      "Indore: First Index = 189, Count = 4872\n",
      "Agra: First Index = 18, Count = 4684\n",
      "Surat: First Index = 20, Count = 4636\n",
      "Varanasi: First Index = 1, Count = 4606\n",
      "Vadodara: First Index = 43, Count = 4568\n",
      "Hyderabad: First Index = 23, Count = 4496\n",
      "Kanpur: First Index = 4, Count = 4398\n",
      "Jaipur: First Index = 12, Count = 4328\n",
      "Thane: First Index = 6, Count = 4289\n",
      "Lucknow: First Index = 16, Count = 4280\n",
      "Nagpur: First Index = 37, Count = 4209\n",
      "Bangalore: First Index = 8, Count = 4123\n",
      "Chennai: First Index = 34, Count = 4044\n",
      "Ghaziabad: First Index = 27, Count = 3620\n",
      "Delhi: First Index = 76, Count = 3593\n",
      "Bhopal: First Index = 141, Count = 3475\n",
      "Faridabad: First Index = 21, Count = 3268\n",
      "Nashik: First Index = 7, Count = 3144\n",
      "Mihir: First Index = 44166, Count = 7\n",
      "Nandini: First Index = 32706, Count = 4\n",
      "Mahi: First Index = 76335, Count = 3\n",
      "Vidya: First Index = 52500, Count = 3\n",
      "City: First Index = 34300, Count = 3\n",
      "Pratyush: First Index = 34247, Count = 3\n",
      "Harsha: First Index = 15181, Count = 3\n",
      "Saanvi: First Index = 22293, Count = 3\n",
      "Bhavna: First Index = 28862, Count = 3\n",
      "Molkata: First Index = 100610, Count = 2\n",
      "MCA: First Index = 38232, Count = 2\n",
      "M.Com: First Index = 33276, Count = 2\n",
      "Atharv: First Index = 33447, Count = 2\n",
      "Nalini: First Index = 17337, Count = 2\n",
      "Keshav: First Index = 12371, Count = 2\n",
      "Ayush: First Index = 2123, Count = 2\n",
      "M.Tech: First Index = 28672, Count = 1\n",
      "Researcher: First Index = 105684, Count = 1\n",
      "Vaishnavi: First Index = 73571, Count = 1\n",
      "Chhavi: First Index = 74881, Count = 1\n",
      "Parth: First Index = 75591, Count = 1\n",
      "Vidhi: First Index = 1190, Count = 1\n",
      "Tushar: First Index = 77791, Count = 1\n",
      "MSc: First Index = 82304, Count = 1\n",
      "No: First Index = 82472, Count = 1\n",
      "Rashi: First Index = 86723, Count = 1\n",
      "ME: First Index = 93066, Count = 1\n",
      "Ishanabad: First Index = 762, Count = 1\n",
      "Armaan: First Index = 109183, Count = 1\n",
      "Kagan: First Index = 106809, Count = 1\n",
      "Kashish: First Index = 71995, Count = 1\n",
      "Ithal: First Index = 112975, Count = 1\n",
      "Nalyan: First Index = 115761, Count = 1\n",
      "Dhruv: First Index = 116546, Count = 1\n",
      "Galesabad: First Index = 117760, Count = 1\n",
      "Itheg: First Index = 121908, Count = 1\n",
      "Aaradhya: First Index = 123642, Count = 1\n",
      "Pooja: First Index = 124395, Count = 1\n",
      "Khushi: First Index = 125289, Count = 1\n",
      "Khaziabad: First Index = 126752, Count = 1\n",
      "Jhanvi: First Index = 136563, Count = 1\n",
      "Kibara: First Index = 73510, Count = 1\n",
      "Harsh: First Index = 68667, Count = 1\n",
      "Reyansh: First Index = 70407, Count = 1\n",
      "Morena: First Index = 42134, Count = 1\n",
      "Less Delhi: First Index = 30231, Count = 1\n",
      "Malyansh: First Index = 20886, Count = 1\n",
      "Aditya: First Index = 18496, Count = 1\n",
      "Plata: First Index = 33408, Count = 1\n",
      "Aishwarya: First Index = 8772, Count = 1\n",
      "3.0: First Index = 35309, Count = 1\n",
      "Less than 5 Kalyan: First Index = 36993, Count = 1\n",
      "Krishna: First Index = 3753, Count = 1\n",
      "Mira: First Index = 38817, Count = 1\n",
      "Moreadhyay: First Index = 39217, Count = 1\n",
      "Ishkarsh: First Index = 42470, Count = 1\n",
      "Raghavendra: First Index = 22215, Count = 1\n",
      "Kashk: First Index = 43050, Count = 1\n",
      "Gurgaon: First Index = 3554, Count = 1\n",
      "Tolkata: First Index = 53366, Count = 1\n",
      "Anvi: First Index = 55970, Count = 1\n",
      "Krinda: First Index = 57185, Count = 1\n",
      "Ayansh: First Index = 58776, Count = 1\n",
      "Shrey: First Index = 60210, Count = 1\n",
      "Ivaan: First Index = 61687, Count = 1\n",
      "Vaanya: First Index = 63830, Count = 1\n",
      "Gaurav: First Index = 65042, Count = 1\n",
      "Unirar: First Index = 138190, Count = 1\n",
      "Total unique cities: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/yqb_d2815j15ggfbmhgbj8gh0000gn/T/ipykernel_64023/1198885951.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  first_occurrence = data.groupby(\"City\").apply(lambda x: x.index[0])\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each unique city\n",
    "city_counts = data[\"City\"].value_counts()\n",
    "\n",
    "# Find first occurrence index for each unique city\n",
    "first_occurrence = data.groupby(\"City\").apply(lambda x: x.index[0])\n",
    "\n",
    "# Sort cities by count in descending order\n",
    "sorted_cities = city_counts.index  # Cities sorted by count (default sorting from most to least)\n",
    "\n",
    "count = 0\n",
    "# Print results\n",
    "print(\"Unique cities sorted by count (most to least):\")\n",
    "for city in sorted_cities:\n",
    "    if city_counts[city] > 0:\n",
    "        count += 1\n",
    "        print(f\"{city}: First Index = {first_occurrence[city]}, Count = {city_counts[city]}\")\n",
    "\n",
    "print(f\"Total unique cities: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found population, density, literacy and sex ratio for each major city in our dataset. We then merged this in our data and removed city column. For the minor cities or the wrongly written cities we took the average of the other columns..\n",
    "\n",
    "# Financial Stress (No preprocessing needed here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Unique sleep sorted by count (most to least):\n",
      "2.0 31451\n",
      "5.0 28279\n",
      "4.0 27765\n",
      "1.0 27211\n",
      "3.0 25990\n"
     ]
    }
   ],
   "source": [
    "finans_count = data[\"Financial Stress\"].value_counts()\n",
    "print(data[\"Financial Stress\"].nunique())\n",
    "\n",
    "print(\"Unique sleep sorted by count (most to least):\")\n",
    "for e, (fn, count) in enumerate(finans_count.items()):\n",
    "    print(fn, count)\n",
    "    if e == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work Study Hours (No prerocessing needed here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Unique Work/Study Hours sorted by count (most to least):\n",
      "10.0 14199\n",
      "11.0 12832\n",
      "9.0 12711\n",
      "0.0 12066\n",
      "12.0 11409\n",
      "2.0 10595\n",
      "6.0 10432\n",
      "7.0 9872\n",
      "1.0 9802\n",
      "3.0 9474\n",
      "5.0 9337\n",
      "4.0 9065\n",
      "8.0 8906\n"
     ]
    }
   ],
   "source": [
    "ws_counts = data[\"Work/Study Hours\"].value_counts()\n",
    "print(data[\"Work/Study Hours\"].nunique())\n",
    "\n",
    "print(\"Unique Work/Study Hours sorted by count (most to least):\")\n",
    "for e, (ws, count) in enumerate(ws_counts.items()):\n",
    "    print(ws, count)\n",
    "    if e == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the Id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropId(data):\n",
    "\n",
    "    # Drop the 'id' column\n",
    "    data = data.drop(columns=[\"id\"])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_freq(data):\n",
    "    # Replace each name with its frequency in the dataset\n",
    "    data[\"Name\"] = data[\"Name\"].map(data[\"Name\"].value_counts())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding gender column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_encode(data):\n",
    "    data[\"Gender\"] = data[\"Gender\"].map({\"Female\": 0, \"Male\": 1 })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_integer(data):\n",
    "    data[\"Age\"] = data[\"Age\"].astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Academic Preessure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def academic_pressure(data):\n",
    "    data[\"Academic Pressure\"] = np.where(\n",
    "        data[\"Academic Pressure\"].isnull(), 0,\n",
    "        data[\"Academic Pressure\"]\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Family History of Mental Illnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_mental_illness(data):\n",
    "    data[\"Family History of Mental Illness\"] = np.where(\n",
    "        data[\"Family History of Mental Illness\"] == \"No\", 0,\n",
    "        np.where(\n",
    "            data[\"Family History of Mental Illness\"] == \"Yes\", 1,\n",
    "            data[\"Family History of Mental Illness\"]\n",
    "        )\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you ever had suicidal thoughts ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suicidal_thoughts(data):\n",
    "    data[\"Have you ever had suicidal thoughts ?\"] = np.where(\n",
    "        data[\"Have you ever had suicidal thoughts ?\"] == \"No\", 0,\n",
    "        np.where(\n",
    "            data[\"Have you ever had suicidal thoughts ?\"] == \"Yes\", 1,\n",
    "            data[\"Have you ever had suicidal thoughts ?\"]\n",
    "        )\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working Professional or Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def working_or_student(data):\n",
    "    data[\"Working Professional or Student\"] = np.where(\n",
    "        data[\"Working Professional or Student\"] == \"Working Professional\", 0,\n",
    "        np.where(\n",
    "            data[\"Working Professional or Student\"] == \"Student\", 1,\n",
    "            data[\"Working Professional or Student\"]\n",
    "        )\n",
    "    )       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profession(data):\n",
    "    # Count occurrences of each profession\n",
    "    profession_counts = data[\"Profession\"].value_counts()\n",
    "    \n",
    "    # Update the \"Profession\" column\n",
    "    data[\"Profession\"] = np.where(\n",
    "        data[\"Profession\"].isnull() & (data[\"Working Professional or Student\"] == 1),\n",
    "        \"Student\",\n",
    "        np.where(\n",
    "            data[\"Profession\"].isnull() & (data[\"Working Professional or Student\"] == 0), \n",
    "            \"Missing Profession\", \n",
    "            np.where(\n",
    "                data[\"Profession\"].map(profession_counts) < 6,  # If occurrence < 10, set to \"Missing Profession\"\n",
    "                \"Missing Profession\",\n",
    "                data[\"Profession\"]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work_pressure(data):\n",
    "    data[\"Work Pressure\"] = np.where(\n",
    "        data[\"Work Pressure\"].isnull(), 0.0, data[\"Work Pressure\"]\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CGPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cgpa(data):\n",
    "    data[\"CGPA\"] = np.where(\n",
    "        data[\"CGPA\"].isnull(), data[\"CGPA\"].mean(), data[\"CGPA\"]\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study- and Job Satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def satisfaction(data):\n",
    "    satisfaction = np.where(\n",
    "        data[\"Study Satisfaction\"].notnull(), data[\"Study Satisfaction\"], np.where(\n",
    "            data[\"Job Satisfaction\"].notnull(), data[\"Job Satisfaction\"], 0\n",
    "        )\n",
    "    )\n",
    "    data[\"Job Satisfaction\"] = satisfaction\n",
    "    data = data.drop(columns=\"Study Satisfaction\")\n",
    "    data.rename(columns={\"Job Satisfaction\": \"Satisfaction\"}, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sleep Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_duration(data):\n",
    "    data[\"Sleep Duration\"] = np.where(\n",
    "        data[\"Sleep Duration\"] == \"Less than 5 hours\", 1, np.where(\n",
    "            data[\"Sleep Duration\"] == \"5-6 hours\", 2, np.where(\n",
    "                data[\"Sleep Duration\"] == \"7-8 hours\", 3, np.where(\n",
    "                    data[\"Sleep Duration\"] == \"More than 8 hours\", 4, 1\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dietary Habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diet(data):\n",
    "    data[\"Dietary Habits\"] = np.where(\n",
    "        data[\"Dietary Habits\"] == \"Healthy\", 2, np.where(\n",
    "            data[\"Dietary Habits\"] == \"Moderate\", 1, np.where(\n",
    "                data[\"Dietary Habits\"] == \"Unhealthy\", 0, 1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_degree(degree):\n",
    "\n",
    "    \"\"\"\n",
    "    Categorizes the differnet degrees into Schoo, Bachelors, Masters, Doctrate, professional and other\n",
    "    \"\"\"\n",
    "    \n",
    "    degree = str(degree).strip().lower()\n",
    "\n",
    "    # School-Level\n",
    "    if \"class 11\" in degree or \"class 12\" in degree:\n",
    "        return \"School\"\n",
    "\n",
    "    # Bachelor's Degrees\n",
    "    bachelor_keywords = [\"b.\", \"b \", \"bachelor\", \"bcom\", \"bsc\", \"btech\", \"be\", \"bba\", \"bca\", \"ba\", \"b.ed\", \"b.arch\"]\n",
    "    if any(keyword in degree for keyword in bachelor_keywords):\n",
    "        return \"Bachelors\"\n",
    "\n",
    "    # Master's Degrees\n",
    "    master_keywords = [\"m.\", \"m \", \"master\", \"mba\", \"mcom\", \"msc\", \"mtech\", \"me\", \"mca\", \"m.ed\", \"mpharm\", \"m.arch\"]\n",
    "    if any(keyword in degree for keyword in master_keywords):\n",
    "        return \"Masters\"\n",
    "\n",
    "    # Doctoral Degrees\n",
    "    if \"phd\" in degree:\n",
    "        return \"Doctorate\"\n",
    "\n",
    "    # Professional Degrees\n",
    "    professional_keywords = [\"mbbs\", \"md\", \"llb\", \"llm\"]\n",
    "    if any(keyword in degree for keyword in professional_keywords):\n",
    "        return \"Professional\"\n",
    "\n",
    "    # Unknown / Noisy Data\n",
    "    return \"Other\"\n",
    "\n",
    "def degree(data):\n",
    "    \n",
    "    # Apply categorization\n",
    "    data[\"Degree\"] = data[\"Degree\"].apply(categorize_degree)\n",
    "\n",
    "\n",
    "    # Define an ordinal mapping\n",
    "    degree_mapping = {\n",
    "        \"School\": 0,\n",
    "        \"Bachelors\": 1,\n",
    "        \"Masters\": 2,\n",
    "        \"Professional\": 3,\n",
    "        \"Doctorate\": 4,\n",
    "        \"Other\": -1  # Keep 'Other' at the highest level or remove it depending on the approach\n",
    "    }\n",
    "\n",
    "    # Apply mapping\n",
    "    data[\"Degree\"] = data[\"Degree\"].map(degree_mapping)\n",
    "\n",
    "    return data \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorizing Professions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize professions into broader industry groups\n",
    "def categorize_profession(profession):\n",
    "    if pd.isna(profession) or \"missing\" in profession.lower():\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    profession = profession.lower().strip()\n",
    "\n",
    "    # Technology\n",
    "    tech_keywords = [\"software\", \"data scientist\", \"ux/ui\", \"developer\", \"engineer\"]\n",
    "    if any(keyword in profession for keyword in tech_keywords):\n",
    "        return \"Technology\"\n",
    "\n",
    "    # Finance\n",
    "    finance_keywords = [\"accountant\", \"financial\", \"investment\", \"banker\", \"analyst\"]\n",
    "    if any(keyword in profession for keyword in finance_keywords):\n",
    "        return \"Finance\"\n",
    "\n",
    "    # Healthcare\n",
    "    healthcare_keywords = [\"doctor\", \"pharmacist\", \"dentist\", \"nurse\"]\n",
    "    if any(keyword in profession for keyword in healthcare_keywords):\n",
    "        return \"Healthcare\"\n",
    "\n",
    "    # Education\n",
    "    education_keywords = [\"teacher\", \"professor\", \"educational\"]\n",
    "    if any(keyword in profession for keyword in education_keywords):\n",
    "        return \"Education\"\n",
    "\n",
    "    # Engineering\n",
    "    engineering_keywords = [\"civil engineer\", \"mechanical engineer\", \"architect\"]\n",
    "    if any(keyword in profession for keyword in engineering_keywords):\n",
    "        return \"Engineering\"\n",
    "\n",
    "    # Marketing & Sales\n",
    "    marketing_keywords = [\"marketing\", \"sales\", \"digital marketer\", \"content writer\"]\n",
    "    if any(keyword in profession for keyword in marketing_keywords):\n",
    "        return \"Marketing/Sales\"\n",
    "\n",
    "    # Trade & Manual Work\n",
    "    trade_keywords = [\"electrician\", \"plumber\", \"chef\", \"mechanic\"]\n",
    "    if any(keyword in profession for keyword in trade_keywords):\n",
    "        return \"Trade\"\n",
    "\n",
    "    # Legal\n",
    "    legal_keywords = [\"lawyer\", \"judge\", \"legal\"]\n",
    "    if any(keyword in profession for keyword in legal_keywords):\n",
    "        return \"Legal\"\n",
    "\n",
    "    # Consulting\n",
    "    consulting_keywords = [\"consultant\", \"business analyst\"]\n",
    "    if any(keyword in profession for keyword in consulting_keywords):\n",
    "        return \"Consulting\"\n",
    "\n",
    "    # Other / Unknown\n",
    "    return \"Other\"\n",
    "\n",
    "def Prefession_categorization(data):\n",
    "    # Apply categorization\n",
    "    data[\"Profession_Category\"] = data[\"Profession\"].apply(categorize_profession)\n",
    "\n",
    "    # Encoding Options\n",
    "\n",
    "    ## Option 1: Ordinal Encoding (useful if there's a natural order)\n",
    "    profession_mapping = {\n",
    "        \"Unknown\": 0,\n",
    "        \"Other\": 1,\n",
    "        \"Trade\": 2,\n",
    "        \"Marketing/Sales\": 3,\n",
    "        \"Consulting\": 4,\n",
    "        \"Education\": 5,\n",
    "        \"Finance\": 6,\n",
    "        \"Engineering\": 7,\n",
    "        \"Healthcare\": 8,\n",
    "        \"Legal\": 9,\n",
    "        \"Technology\": 10\n",
    "    }\n",
    "\n",
    "    data[\"Profession_Encoded\"] = data[\"Profession_Category\"].map(profession_mapping)\n",
    "\n",
    "    data[\"Profession\"] = data[\"Profession_Encoded\"]\n",
    "\n",
    "    data = data.drop(columns=[\"Profession_Encoded\", \"Profession_Category\"])\n",
    "    return data\n",
    "    ## Option 2: One-Hot Encoding (better for categorical data)\n",
    "    # data = pd.get_dummies(data, columns=[\"Profession_Category\"], prefix=\"Profession\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load city data (assuming it's already loaded in a DataFrame named df_cities)\n",
    "city_data_path = \"./Data/indian_cities_data.csv\"\n",
    "df_cities = pd.read_csv(city_data_path)\n",
    "\n",
    "def city_one_hot(data):\n",
    "    # Find the index of the \"City\" column\n",
    "    city_index = data.columns.get_loc(\"City\")\n",
    "\n",
    "    # Merge the data with city information, excluding \"Main Language\"\n",
    "    merged_data = data.merge(df_cities.drop(columns=[\"Main Language\"]), on=\"City\", how=\"left\")\n",
    "\n",
    "    # Calculate the mean values for missing cities\n",
    "    mean_values = merged_data[[\"Population\", \"Density (per km²)\", \"Literacy Rate (%)\", \"Sex Ratio\"]].mean()\n",
    "\n",
    "    # Replace NaN values with the mean of the respective column\n",
    "    merged_data.fillna(mean_values, inplace=True)\n",
    "\n",
    "    # Drop the original \"City\" column\n",
    "    merged_data.drop(columns=[\"City\"], inplace=True)\n",
    "\n",
    "    # Reorder columns to place new city-related columns where \"City\" was\n",
    "    city_columns = [\"Population\", \"Density (per km²)\", \"Literacy Rate (%)\", \"Sex Ratio\"]\n",
    "    cols = merged_data.columns.tolist()\n",
    "\n",
    "    # Move the new city-related columns to the correct index\n",
    "    for col in reversed(city_columns):\n",
    "        cols.insert(city_index, cols.pop(cols.index(col)))\n",
    "\n",
    "    # Reorder the dataframe\n",
    "    merged_data = merged_data[cols]\n",
    "\n",
    "    return merged_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Gender  Age  Population  Density (per km²)  Literacy Rate (%)  \\\n",
      "0  2045       0   49   1618879.0             5200.0              85.77   \n",
      "1   963       1   26   1198491.0             7300.0              79.27   \n",
      "2   730       1   33   1728128.0             2500.0              81.79   \n",
      "3   730       1   22  12442373.0            20482.0              89.73   \n",
      "4   499       0   30   2765348.0             6900.0              82.42   \n",
      "\n",
      "   Sex Ratio Working Professional or Student  Profession  Academic Pressure  \\\n",
      "0      850.0                               0           2                0.0   \n",
      "1      887.0                               0           5                0.0   \n",
      "2      978.0                               1           1                5.0   \n",
      "3      853.0                               0           5                0.0   \n",
      "4      857.0                               0           6                0.0   \n",
      "\n",
      "   ...      CGPA  Satisfaction  Sleep Duration  Dietary Habits  Degree  \\\n",
      "0  ...  7.658636           2.0               4               2      -1   \n",
      "1  ...  7.658636           3.0               1               0       3   \n",
      "2  ...  8.970000           2.0               2               2       1   \n",
      "3  ...  7.658636           1.0               1               1       1   \n",
      "4  ...  7.658636           1.0               2               0       1   \n",
      "\n",
      "   Have you ever had suicidal thoughts ? Work/Study Hours  Financial Stress  \\\n",
      "0                                      0              1.0               2.0   \n",
      "1                                      1              7.0               3.0   \n",
      "2                                      1              3.0               1.0   \n",
      "3                                      1             10.0               1.0   \n",
      "4                                      1              9.0               4.0   \n",
      "\n",
      "   Family History of Mental Illness Depression  \n",
      "0                                 0          0  \n",
      "1                                 0          1  \n",
      "2                                 0          1  \n",
      "3                                 1          1  \n",
      "4                                 1          0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Unique names sorted by count (most to least):\n",
      "1: 65314\n",
      "2: 31530\n",
      "3: 15460\n",
      "0: 14730\n",
      "-1: 10563\n",
      "4: 3103\n",
      "Total unique names: 6\n"
     ]
    }
   ],
   "source": [
    "def pre_processing(data):\n",
    "\n",
    "    data = dropId(data)\n",
    "    data = name_freq(data)\n",
    "    data = gender_encode(data)\n",
    "    data = age_integer(data)\n",
    "    data = academic_pressure(data)\n",
    "    data = family_mental_illness(data)\n",
    "    data = suicidal_thoughts(data)\n",
    "    data = working_or_student(data)\n",
    "    data = profession(data)\n",
    "    data = work_pressure(data)\n",
    "    data = cgpa(data)\n",
    "    data = satisfaction(data)\n",
    "    data = sleep_duration(data)\n",
    "    data = diet(data)\n",
    "    data = degree(data)\n",
    "    data = Prefession_categorization(data)\n",
    "    data = city_one_hot(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "data = pre_processing(data)\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "name_counts = data[\"Degree\"].value_counts()\n",
    "\n",
    "print(\"Unique names sorted by count (most to least):\")\n",
    "for name, count in name_counts.items():\n",
    "    print(f\"{name}: {count}\")\n",
    "\n",
    "print(f\"Total unique names: {len(name_counts)}\")\n",
    "\n",
    "data.to_csv(\"preprocessed_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF367A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
